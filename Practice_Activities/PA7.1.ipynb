{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Practice Activity 7.1\n",
    "author: Will Kapner\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        code-fold: true\n",
    "output: html\n",
    "warning: false\n",
    "echo: true\n",
    "embed-resources: true\n",
    "eval: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider four possible models for predicting house prices:\n",
    "\n",
    "Using only the size and number of rooms.\n",
    "Using size, number of rooms, and building type.\n",
    "Using size and building type, and their interaction.\n",
    "Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
    "Set up a pipeline for each of these four models.\n",
    "\n",
    "Then, get predictions on the test set for each of your pipelines, and compute the root mean squared error. Which model performed best?\n",
    "\n",
    "Note: You should only use the function train_test_split() one time in your code; that is, we should be predicting on the same test set for all three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "housing = pd.read_csv(\"/Users/williamkapner/Documents/GSB_544/Data/AmesHousing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.drop(\"SalePrice\", axis = 1)\n",
    "y = housing[\"SalePrice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Squared: 0.5375267745996803\n",
      "Cross Validation RMSE: 55174.98589881498\n",
      "Slope: [ 71638.1428861  -21582.11735524]\n",
      "Intercept: 180368.25079654073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "lr_fitted = lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predictions for train and test sets\n",
    "y_train_pred = lr_fitted.predict(X_train)\n",
    "y_test_pred = lr_fitted.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate MSE for training and testing data\n",
    "r1 = r2_score(y_test, y_test_pred)\n",
    "intercept1 = lr_fitted.named_steps['linear_regression'].intercept_\n",
    "coefficients1 = lr_fitted.named_steps['linear_regression'].coef_\n",
    "crossval1 = cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rmse1 = np.sqrt(-crossval1)\n",
    "mse1 = sk.metrics.mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R_Squared:\", r1)\n",
    "print(\"Cross Validation RMSE:\", rmse1.mean())\n",
    "print(\"Slope:\", coefficients1)\n",
    "print(\"Intercept:\", intercept1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Squared: 0.5633220861145007\n",
      "Cross Validation RMSE: 53356.75472657602\n",
      "Slope: [ 6.60201811e+04 -1.35416646e+04  1.24597206e+18  1.24597206e+18\n",
      "  1.24597206e+18  1.24597206e+18  1.24597206e+18]\n",
      "Intercept: -1.2459720553600315e+18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct1 = ColumnTransformer(\n",
    "  [  \n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"]),\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct1),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n",
    "\n",
    "\n",
    "lr_fitted = lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions for train and test sets\n",
    "y_train_pred = lr_fitted.predict(X_train)\n",
    "y_test_pred = lr_fitted.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate MSE for training and testing data\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "intercept2 = lr_fitted.named_steps['linear_regression'].intercept_\n",
    "coefficients2 = lr_fitted.named_steps['linear_regression'].coef_\n",
    "crossval2 = cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rmse2 = np.sqrt(-crossval2)\n",
    "mse2 = sk.metrics.mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R_Squared:\", r2)\n",
    "print(\"Cross Validation RMSE:\", rmse2.mean())\n",
    "print(\"Slope:\", coefficients2)\n",
    "print(\"Intercept:\", intercept2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Squared: 0.5890797792502362\n",
      "Cross Validation RMSE: 52879.46201230896\n",
      "Slope: [ 0.00000000e+00 -7.52649751e+17 -1.44688592e+17 -3.80625004e+15\n",
      "  6.87808878e+15  1.78432192e+17 -1.44688592e+17 -3.80625004e+15\n",
      " -7.08403340e+15  1.93006395e+17 -1.44688592e+17 -3.80625004e+15\n",
      "  0.00000000e+00  1.92508707e+17 -1.44688592e+17 -3.80625004e+15\n",
      "  7.10542736e-15  1.92508707e+17 -1.44688592e+17 -3.80625004e+15]\n",
      "Intercept: 1.4489453647987766e+17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct2 = ColumnTransformer(\n",
    "  [  \n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\"]),\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "X_train_dummified = ct2.fit_transform(X_train)\n",
    "X_train_dummified\n",
    "\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    (\"interaction\", PolynomialFeatures(interaction_only = True), [\"standardize__Gr Liv Area\", \"dummify__Bldg Type_1Fam\"]),\n",
    "    (\"interaction1\", PolynomialFeatures(interaction_only = True), [\"standardize__Gr Liv Area\", \"dummify__Bldg Type_2fmCon\"]),\n",
    "    (\"interaction2\", PolynomialFeatures(interaction_only = True), [\"standardize__Gr Liv Area\", \"dummify__Bldg Type_Duplex\"]),\n",
    "    (\"interaction3\", PolynomialFeatures(interaction_only = True), [\"standardize__Gr Liv Area\", \"dummify__Bldg Type_Twnhs\"]),\n",
    "    (\"interaction4\", PolynomialFeatures(interaction_only = True), [\"standardize__Gr Liv Area\", \"dummify__Bldg Type_TwnhsE\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct2),\n",
    "   (\"interactions\", ct_inter),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n",
    "\n",
    "\n",
    "lr_fitted = lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions for train and test sets\n",
    "y_test_pred = lr_fitted.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate MSE for training and testing data\n",
    "r3 = r2_score(y_test, y_test_pred)\n",
    "intercept3 = lr_fitted.named_steps['linear_regression'].intercept_\n",
    "coefficients3 = lr_fitted.named_steps['linear_regression'].coef_\n",
    "crossval3 = cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rmse3 = np.sqrt(-crossval3)\n",
    "mse3 = sk.metrics.mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R_Squared:\", r3)\n",
    "print(\"Cross Validation RMSE:\", rmse3.mean())\n",
    "print(\"Slope:\", coefficients3)\n",
    "print(\"Intercept:\", intercept3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3371980394.7024097\n",
      "R_Squared: 0.5258861594220923\n",
      "Cross Validation RMSE: 63529.84906106508\n",
      "Slope: [-1.77530999e-02  7.66181573e-02 -5.71975377e-02 -6.72248502e-03\n",
      "  2.00386856e-01 -4.05233041e+00 -2.71905433e-02 -1.57383110e-04\n",
      "  3.41533143e-02 -7.03398539e+00  3.53346589e-02 -5.32979098e-10\n",
      "  3.27767823e-05 -1.28481968e-02  1.82905671e+00  1.07229452e+00\n",
      "  3.45791324e-12 -2.52119728e-09 -1.98851130e-06  1.36667988e-03\n",
      " -2.52953253e-01  1.04901008e+01 -2.70351590e-03  5.52595254e-05\n",
      " -3.96057818e-04  1.17196476e-03  1.87234942e-03]\n",
      "Intercept: 48570.88673762488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct3 = ColumnTransformer(\n",
    "  [  \n",
    "    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"]),\n",
    "    ('polynomial_features', PolynomialFeatures(degree=5, include_bias=False), [\"Gr Liv Area\", \"TotRms AbvGrd\"]),\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct3),\n",
    "   \n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n",
    "\n",
    "\n",
    "lr_fitted = lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions for train and test sets\n",
    "y_test_pred = lr_fitted.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate MSE for training and testing data\n",
    "r4 = r2_score(y_test, y_test_pred)\n",
    "intercept4 = lr_fitted.named_steps['linear_regression'].intercept_\n",
    "coefficients4 = lr_fitted.named_steps['linear_regression'].coef_\n",
    "crossval4 = cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rmse4 = np.sqrt(-crossval4)\n",
    "mse4 = sk.metrics.mean_squared_error(y_test, y_test_pred)\n",
    "print(mse4)\n",
    "\n",
    "print(\"R_Squared:\", r4)\n",
    "print(\"Cross Validation RMSE:\", rmse4.mean())\n",
    "print(\"Slope:\", coefficients4)\n",
    "print(\"Intercept:\", intercept4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>57351.462994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>55729.072748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>54060.487785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>58068.755753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model          RMSE\n",
       "0  Model 1  57351.462994\n",
       "1  Model 2  55729.072748\n",
       "2  Model 3  54060.487785\n",
       "3  Model 4  58068.755753"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = {\"Model\": [\"Model 1\", \"Model 2\",\"Model 3\",\"Model 4\"],\n",
    "         \"RMSE\": [np.sqrt(mse1),np.sqrt(mse2),np.sqrt(mse3),np.sqrt(mse4)]}\n",
    "\n",
    "pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that Model 3 was the best model. It included interactions which helped reduce the unexplained error in the model and gave us the smallest RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run the same models using cross validation. The code for the cross validations are included in the code chunks from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>55174.985899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>53356.754727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>52879.462012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>63529.849061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Cross Validation RMSE\n",
       "0  Model 1           55174.985899\n",
       "1  Model 2           53356.754727\n",
       "2  Model 3           52879.462012\n",
       "3  Model 4           63529.849061"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = {\"Model\": [\"Model 1\", \"Model 2\",\"Model 3\",\"Model 4\"],\n",
    "         \"Cross Validation RMSE\": [rmse1.mean(),rmse2.mean(),rmse3.mean(),rmse4.mean()]}\n",
    "\n",
    "pd.DataFrame(table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, after performing cross validation, Model 3 is still the best model because it has the smallest RMSE after cross validation. This is more powerful than our calculation from Part 1, and confirms that Model 3 with the interactions has the more accurate predictions. This agrees with my earlier conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will create 100 different models with degrees 1 to 10 for the living area and number of rooms variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ct_poly = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"polynomial_area\", PolynomialFeatures(), [\"Gr Liv Area\"]),\n",
    "    (\"polynomial_rooms\", PolynomialFeatures(), [\"TotRms AbvGrd\"])\n",
    "    \n",
    "\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "lr_pipeline_poly = Pipeline(\n",
    "  [(\"preprocessing\", ct_poly),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "degrees = {'preprocessing__polynomial_area__degree': np.arange(1, 11),\n",
    "           'preprocessing__polynomial_rooms__degree': np.arange(1, 11)}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_poly, degrees, cv = 5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "#gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gscv_fitted.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "degree_area               3\n",
       "degree_rooms              1\n",
       "mean_test_score    0.557641\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = gscv.cv_results_\n",
    "\n",
    "# Create a DataFrame with the degree combinations and corresponding mean test scores\n",
    "df_results = pd.DataFrame({\n",
    "    \"degree_area\": results['param_preprocessing__polynomial_area__degree'],\n",
    "    \"degree_rooms\": results['param_preprocessing__polynomial_rooms__degree'],\n",
    "    \"mean_test_score\": results['mean_test_score']\n",
    "})\n",
    "\n",
    "df_results\n",
    "df_results.loc[df_results['mean_test_score'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:\n",
    "The best model had an R-Squared value of about 0.56 after cross validation. This occurred with an area degree of 3, a room degree of 1, and building type in the model. These R-Squared values were calculated using cross validation with 5 folds, and we picked from 100 possible models.\n",
    "\n",
    "Q2:\n",
    "Some of the downsides of finding this many models are it takes awhile to run, and there is a factor of randomness to it. Since there are so many models, there is a good chance that one of them just happened to perform the best on this test set and might not have actually been the best model. Using this many models also includes a risk of overfitting the model. It's best to find smaller subsets to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat GPT 4o was used to debug some syntax errors and to help create a table for 100 models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
